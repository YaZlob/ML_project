{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "\"OD_diplom.ipynb\"",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZAPMGZNkCd-"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBynfbFpkQXk"
      },
      "source": [
        "!unzip -q /content/gdrive/MyDrive/Диплом/Dataset.zip -d dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqEVZHzNkh72"
      },
      "source": [
        "import torch\r\n",
        "import os\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import copy\r\n",
        "\r\n",
        "from matplotlib import colors, pyplot as plt\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchvision import transforms\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from PIL import Image\r\n",
        "from torchvision import models\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "from matplotlib.patches import Rectangle\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1suia3eOk3Ji"
      },
      "source": [
        "random.seed(0)\r\n",
        "torch.manual_seed(0)\r\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhqmZkDEt3mM"
      },
      "source": [
        "main_path = os.path.join(\"dataset/Dataset\")\r\n",
        "images_path = os.path.join(main_path,\"image\")\r\n",
        "labels_path = os.path.join(main_path,\"label\")\r\n",
        "bboxes = ['apple_bbox.txt','bottle_bbox.txt','yogurt_bbox.txt']\r\n",
        "images = ['apple', 'bottle', 'yogurt','empty']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRw2oTZhKHBF"
      },
      "source": [
        "bboxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD0Eg6j8CI3M"
      },
      "source": [
        "def upload_bbox(l_path:str, item):\r\n",
        "  path = os.path.join(l_path,item)\r\n",
        "  with open(path,\"r\") as f:\r\n",
        "    bbox_array = [list(map(float, i[:-1].split())) for i in f.readlines()]\r\n",
        "    return bbox_array\r\n",
        "\r\n",
        "def upload_image(im_path, item):\r\n",
        "    print(f\"upload: {item}\")\r\n",
        "    path = os.path.join(im_path, item)\r\n",
        "    image_num = [f\"{i + 1}.jpg\" for i in range(len(os.listdir(path)))]\r\n",
        "    return [os.path.join(path, i) for i in image_num]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebMGwfZCFzyU"
      },
      "source": [
        "a = upload_bbox(labels_path,bboxes[0])\r\n",
        "b = upload_image(images_path,images[0])\r\n",
        "assert len(a) == len(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEuYA6-B1npE"
      },
      "source": [
        "def normalize(image: Image, mean: list, std : list):\r\n",
        "    transform = transforms.Compose([ transforms.ToTensor(),\r\n",
        "                         transforms.Normalize(mean, std)])\r\n",
        "    return transform(image)\r\n",
        "\r\n",
        "def create_dataset(im_list, mean, std):\r\n",
        "    new_dataset = []\r\n",
        "    for index, item in enumerate(im_list):\r\n",
        "        path = os.path.join(images_path,item)\r\n",
        "        if index == 3:\r\n",
        "            # numbering is not important\r\n",
        "            for image in os.listdir(path):\r\n",
        "                image = normalize(Image.open(image_name),mean,std)\r\n",
        "                new_dataset.append((image,index, torch.Tensor([0,0,0,0])))\r\n",
        "        else:\r\n",
        "            bbox = upload_bbox(labels_path,bboxes[index])\r\n",
        "            for i in range(len(os.listdir(path))):\r\n",
        "                image_name = os.path.join(path,f\"{str(i+1)}.jpg\")\r\n",
        "                image = normalize(Image.open(image_name),mean,std)\r\n",
        "                t_bbox = torch.Tensor(bbox[i])\r\n",
        "                new_dataset.append((image,index,t_bbox))\r\n",
        "    return new_dataset\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3JqRkViZR8O"
      },
      "source": [
        "data = create_dataset(images,[0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfJ-02dk7pGp"
      },
      "source": [
        "for image,label,bbox in data:\r\n",
        "  print(type(image))\r\n",
        "  print(type(label))\r\n",
        "  print(type(bbox))\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3XqMyeIa9-w"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train_dataset, val_test_dataset = train_test_split(data,test_size = 0.35, shuffle =True,random_state=42)\r\n",
        "print(f\"Размер тренировочного датасета {len(train_dataset)} изображений\")\r\n",
        "print(f\"Размер валидационного датасета {len(val_test_dataset)} изображений\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEKIIfjRCWA4"
      },
      "source": [
        "class ForDataLoader():\r\n",
        "    def __init__(self,dataset):\r\n",
        "        self.data = dataset\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.data)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        x = self.data[idx][0]\r\n",
        "        y_class = self.data[idx][1]\r\n",
        "        y_bb = self.data[idx][2]\r\n",
        "        return x, y_class, y_bb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi4C2tiX-2JA"
      },
      "source": [
        "k1 = ForDataLoader(train_dataset)\r\n",
        "k2 = ForDataLoader(val_test_dataset)\r\n",
        "train_loader = DataLoader(k1,\r\n",
        "                          batch_size = 16,\r\n",
        "                          shuffle=True)\r\n",
        "val_loader = DataLoader(k2,\r\n",
        "                          batch_size = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHqjXvN3FMUh"
      },
      "source": [
        "for image,y,bbox in train_loader:\r\n",
        "  print(image.shape)\r\n",
        "  print(y.shape)\r\n",
        "  print(bbox.shape)\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-1RZDJO6QGo"
      },
      "source": [
        "class BB_model(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(BB_model, self).__init__()\r\n",
        "        resnet = models.resnet34(pretrained=True)\r\n",
        "        layers = list(resnet.children())[:8]\r\n",
        "        self.features1 = nn.Sequential(*layers[:6])\r\n",
        "        self.features2 = nn.Sequential(*layers[6:])\r\n",
        "        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4),nn.Sigmoid())\r\n",
        "        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512,4))\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.features1(x).to(device)\r\n",
        "        x = self.features2(x).to(device)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = nn.AdaptiveAvgPool2d((1,1))(x)\r\n",
        "        x = x.view(x.shape[0], -1)\r\n",
        "        return self.classifier(x).to(device), self.bb(x).to(device)\r\n",
        "model = BB_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Ys-EM89evP"
      },
      "source": [
        "#from torchsummary import summary\r\n",
        "#summary(model.cuda(), (3, 256, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6WrSornMKTD"
      },
      "source": [
        "def update_optimizer(optimizer, lr):\r\n",
        "    for i, param_group in enumerate(optimizer.param_groups):\r\n",
        "        param_group[\"lr\"] = lr\r\n",
        "\r\n",
        "def show_graph(hist):\r\n",
        "    t_loss,v_loss,t_acc,v_acc = [], [], [], []\r\n",
        "    for train_loss,val_loss,train_acc,val_acc in hist:\r\n",
        "        t_loss.append(train_loss)\r\n",
        "        v_loss.append(val_loss)\r\n",
        "        t_acc.append(train_acc)\r\n",
        "        v_acc.append(val_acc)\r\n",
        "\r\n",
        "    fig = plt.figure(figsize=(16,16))\r\n",
        "    ax1 = plt.subplot2grid((2,1), (0,0))\r\n",
        "    ax2 = plt.subplot2grid((2,1), (1,0), sharex=ax1)\r\n",
        "\r\n",
        "    ax1.plot(t_loss, label=\"train_loss\")\r\n",
        "    ax1.plot(v_loss, label=\"val_loss\")\r\n",
        "    ax1.legend(loc=2)\r\n",
        "    ax2.plot(t_acc, label=\"train_acc\")\r\n",
        "    ax2.plot(v_acc, label=\"val_acc\")\r\n",
        "    ax2.legend(loc=2)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "model = BB_model().cuda()\r\n",
        "parameters = filter(lambda p: p.requires_grad, model.parameters())\r\n",
        "optimizer = torch.optim.Adam(parameters, lr=0.003)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E62dTbfjOtJY"
      },
      "source": [
        "def save_model(model,acc,path):\r\n",
        "    if not(os.path.exists(path)):\r\n",
        "        os.mkdir(path)\r\n",
        "    torch.save(model.state_dict(),os.path.join(path,str(acc)+\".pth\"))\r\n",
        "    \r\n",
        "\r\n",
        "def val_metrics(model, class_loss, bbox_loss, valid_dl, C=1000, const = -1,flag = False):\r\n",
        "    model.eval()\r\n",
        "    total, sum_loss, correct = 0, 0, 0 \r\n",
        "    for x, y_class, y_bb in valid_dl:\r\n",
        "\r\n",
        "        batch = y_class.shape[0]\r\n",
        "        x = x.to(device).float()\r\n",
        "        y_class = y_class.to(device)\r\n",
        "        y_bb = y_bb.to(device).float()\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            out_class, out_bb = model(x)\r\n",
        "            loss_class = class_loss(out_class, y_class, reduction=\"sum\")\r\n",
        "            loss_bb = bbox_loss(out_bb, y_bb, reduction=\"none\").sum(1)\r\n",
        "            loss_bb = loss_bb.sum()\r\n",
        "            loss = loss_class + loss_bb/C\r\n",
        "        _, pred = torch.max(out_class, 1)\r\n",
        "        correct += pred.eq(y_class).sum().item()\r\n",
        "        sum_loss += loss.item()\r\n",
        "        total += batch\r\n",
        "    val_correct = correct/total\r\n",
        "    if val_correct >= const and flag:\r\n",
        "        save_model(model,val_correct,path = \"saved_models\")\r\n",
        "        const = val_correct \r\n",
        "    return sum_loss/total, val_correct\r\n",
        "\r\n",
        "def train_epocs(model, optimizer,class_loss, bbox_loss, train_dl, val_dl, epochs=10,C=1000,flag = False):\r\n",
        "    hist = []\r\n",
        "    for i in range(epochs):\r\n",
        "        model.train()\r\n",
        "        total, sum_loss, correct = 0, 0, 0 \r\n",
        "        for x, y_class, y_bb in train_dl:\r\n",
        "            batch = y_class.shape[0]\r\n",
        "            x = x.to(device).float()\r\n",
        "            y_class = y_class.to(device)\r\n",
        "            y_bb = y_bb.to(device).float()\r\n",
        "            full_loss = torch.Tensor()\r\n",
        "            out_class, out_bb = model(x)\r\n",
        "\r\n",
        "            loss_bb = bbox_loss(out_bb, y_bb, reduction=\"none\").sum(1)\r\n",
        "            loss_bb = loss_bb.sum()\r\n",
        "            full_loss += (loss_class + loss_bb/C)\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            total += batch\r\n",
        "            sum_loss += loss.item()\r\n",
        "            correct += pred.eq(y_class).sum().item()\r\n",
        "        train_loss = sum_loss/total\r\n",
        "        train_acc = correct/total\r\n",
        "        val_loss, val_acc = val_metrics(model,class_loss, bbox_loss, val_dl, C, flag=flag)\r\n",
        "        hist.append((train_loss,val_loss,train_acc,val_acc))\r\n",
        "        print(\"train_loss %.3f train_acc %.3f val_loss %.3f val_acc %.3f\" % (train_loss, train_acc, val_loss, val_acc))\r\n",
        "    return hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J16qp1TfO3GK"
      },
      "source": [
        "device = torch.device('cuda')\r\n",
        "#class_loss = F.cross_entropy\r\n",
        "#bbox_loss = F.l1_loss\r\n",
        "class_loss == nn.MSELoss()\r\n",
        "bbox_loss == nn.L1Loss()\r\n",
        "history = train_epocs(model.to(device), optimizer,class_loss, bbox_loss, train_loader, val_loader,C =250, epochs=10)\r\n",
        "show_graph(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpLawSQpQEOT"
      },
      "source": [
        "update_optimizer(optimizer, 0.0003)\r\n",
        "bbox_loss = F.mse_loss\r\n",
        "device = \"cuda\"\r\n",
        "history = train_epocs(model.to(device), optimizer,class_loss, bbox_loss, train_loader, val_loader, C=100,epochs=100)\r\n",
        "show_graph(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxsxJ9s_jiGD"
      },
      "source": [
        "update_optimizer(optimizer, 0.0003)\r\n",
        "#bbox_loss = F.l1_loss\r\n",
        "history = train_epocs(model.cuda(), optimizer,class_loss, \r\n",
        "                      bbox_loss, train_loader, val_loader,\r\n",
        "                      flag = True,C=10,epochs=10)\r\n",
        "show_graph(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGD2gUbDKUbc"
      },
      "source": [
        "update_optimizer(optimizer, 0.00001)\r\n",
        "#bbox_loss = F.l1_loss\r\n",
        "history = train_epocs(model.cuda(), optimizer,class_loss, \r\n",
        "                      bbox_loss, train_loader, val_loader,\r\n",
        "                      flag = True,C=10,epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPTyMb5NP6e9"
      },
      "source": [
        "def transform_image(image:torch.Tensor, mean :list, std:list):\n",
        "\n",
        "  image = image * torch.tensor(std).view(3, 1, 1)\n",
        "  image = image + torch.tensor(mean).view(3, 1, 1)\n",
        "  image = transforms.ToPILImage(mode='RGB')(image)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arZidAzHTayr"
      },
      "source": [
        "def show_bbox(bbox_array,color = \"red\"):\r\n",
        "    bbox = bbox_array\r\n",
        "    return Rectangle(bbox[0:2],width=bbox[2]-bbox[0],height=bbox[3]-bbox[1],color=color,fill=False,lw=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REz0NQUq8kT7"
      },
      "source": [
        "def IOU(boxA, boxB):\r\n",
        "\txA = max(boxA[0], boxB[0])\r\n",
        "\tyA = max(boxA[1], boxB[1])\r\n",
        "\txB = min(boxA[2], boxB[2])\r\n",
        "\tyB = min(boxA[3], boxB[3])\r\n",
        "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\r\n",
        "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\r\n",
        "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\r\n",
        "\tiou = interArea / float(boxAArea + boxBArea - interArea)\r\n",
        "\treturn iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U42wrtfRC1L"
      },
      "source": [
        "def show_predict(model,loader):\r\n",
        "  predict_label = [\"Яблоко\", \"Вода\",\"Йогурт\"]\r\n",
        "  num_image = 9\r\n",
        "\r\n",
        "  fig = plt.figure(figsize=(16,16))\r\n",
        "  random_index = np.random.randint(0, len(val_test_dataset),size=9)\r\n",
        "  for i in range(num_image):\r\n",
        "    # part of predict neural network\r\n",
        "    a = fig.add_subplot(3, 3, i + 1)\r\n",
        "    image, label, bbox1 = loader.dataset[random_index[i]]\r\n",
        "    image_for_graph = copy.deepcopy(image)\r\n",
        "    image = image.unsqueeze(0)\r\n",
        "    pred,bbox2 = model(image)\r\n",
        "    predict = pred.argmax(1)\r\n",
        "    #print(predict)\r\n",
        "    bbox2 = bbox2.detach().numpy()\r\n",
        "    #part of visualization\r\n",
        "    image_for_graph = transform_image(image_for_graph,[0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    plt.gca().add_patch(show_bbox(bbox2[0]))\r\n",
        "    plt.imshow(image_for_graph)\r\n",
        "    a.set_title(f\"IOU: {np.around(IOU(bbox1,bbox2[0]))}\\nPredict :{predict_label[int(predict)]}\")\r\n",
        "\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agyttmOKSGGJ"
      },
      "source": [
        "device = \"cpu\"\r\n",
        "show_predict(model.to(device),val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ_vcKpGK3mH"
      },
      "source": [
        "torch.save(model.state_dict(),\"last1.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQDLMmqTOLde"
      },
      "source": [
        "ls\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C276qoufONm7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}